{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以用的程式碼在第一格，其他為測試用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 16:50:15.513779: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-23 16:50:32.720475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-23 16:50:32.728686: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-23 16:51:05.158064: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-23 16:51:05.169819: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-23 16:51:05.169875: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-08-23 16:51:53.101755: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-23 16:51:53.116198: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-23 16:51:53.119340: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-23 16:51:53.122559: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-23 16:51:53.123062: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-08-23 16:51:53.123499: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-08-23 16:51:53.123952: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-23 16:51:53.130287: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-23 16:51:53.130675: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-08-23 16:51:53.135430: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-08-23 16:51:53.239205: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function train_step at 0x7f5a5488b4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function train_step at 0x7f5a5488b4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method MyModel.call of <__main__.MyModel object at 0x7f5ac282ba10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method MyModel.call of <__main__.MyModel object at 0x7f5ac282ba10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 0: Loss = 0.7833027839660645\n",
      "Epoch 100: Loss = 0.5184746384620667\n",
      "Epoch 200: Loss = 0.4087689220905304\n",
      "Epoch 300: Loss = 0.33321067690849304\n",
      "Epoch 400: Loss = 0.2780115008354187\n",
      "Epoch 500: Loss = 0.236094668507576\n",
      "Epoch 600: Loss = 0.20315071940422058\n",
      "Epoch 700: Loss = 0.17657031118869781\n",
      "Epoch 800: Loss = 0.15470485389232635\n",
      "Epoch 900: Loss = 0.13645528256893158\n",
      "Model saved to: ./checkpoint/ckpt-1000\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f5a540dd830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f5a540dd830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f5a4ffb0950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f5a4ffb0950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: save_model/assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#AND模型\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense = tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.dense(x)\n",
    "\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "targets = np.array([[0], [0], [0], [1]], dtype=np.float32)\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory='./checkpoint', max_to_keep=1)\n",
    "\n",
    "@tf.function\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_object(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss = train_step(inputs, targets)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch {}: Loss = {}\".format(epoch, loss))\n",
    "\n",
    "    manager.save()\n",
    "\n",
    "print(\"Model saved to:\", manager.latest_checkpoint)\n",
    "\n",
    "model.save('save_model',save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "底下為測試用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't set the attribute \"weights\", likely because it conflicts with an existing read-only @property of the object. Please choose a different name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/env/tf1.x/lib/python3.8/site-packages/keras/src/engine/base_layer.py:3161\u001b[0m, in \u001b[0;36mLayer.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   3160\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3161\u001b[0m     \u001b[39msuper\u001b[39;49m(tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mtracking\u001b[39m.\u001b[39;49mAutoTrackable, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(\n\u001b[1;32m   3162\u001b[0m         name, value\n\u001b[1;32m   3163\u001b[0m     )\n\u001b[1;32m   3164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m inputs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m], [\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m], [\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m], [\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m]], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     15\u001b[0m targets \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m0\u001b[39m], [\u001b[39m0\u001b[39m], [\u001b[39m0\u001b[39m], [\u001b[39m1\u001b[39m]], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m---> 17\u001b[0m model \u001b[39m=\u001b[39m MyModel()\n\u001b[1;32m     19\u001b[0m loss_object \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy()\n\u001b[1;32m     21\u001b[0m optimizer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m, in \u001b[0;36mMyModel.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[39msuper\u001b[39m(MyModel, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mVariable(tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal([\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m]))\n\u001b[1;32m      8\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mVariable(tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal([\u001b[39m1\u001b[39m]))\n",
      "File \u001b[0;32m~/env/tf1.x/lib/python3.8/site-packages/keras/src/engine/training.py:369\u001b[0m, in \u001b[0;36mModel.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    364\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mIt looks like you are subclassing `Model` and you \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mforgot to call `super().__init__()`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m Always start with this line.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    367\u001b[0m         )\n\u001b[0;32m--> 369\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(name, value)\n",
      "File \u001b[0;32m~/env/tf1.x/lib/python3.8/site-packages/keras/src/engine/base_layer.py:3165\u001b[0m, in \u001b[0;36mLayer.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   3161\u001b[0m         \u001b[39msuper\u001b[39m(tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mtracking\u001b[39m.\u001b[39mAutoTrackable, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(\n\u001b[1;32m   3162\u001b[0m             name, value\n\u001b[1;32m   3163\u001b[0m         )\n\u001b[1;32m   3164\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m-> 3165\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m   3166\u001b[0m             (\n\u001b[1;32m   3167\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mt set the attribute \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, likely because it \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   3168\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mconflicts with an existing read-only @property of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3169\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mobject. Please choose a different name.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3170\u001b[0m             )\u001b[39m.\u001b[39mformat(name)\n\u001b[1;32m   3171\u001b[0m         )\n\u001b[1;32m   3172\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   3174\u001b[0m \u001b[39m# Wraps data structures in `Trackable`, unwraps `NoDependency` objects.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't set the attribute \"weights\", likely because it conflicts with an existing read-only @property of the object. Please choose a different name."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.weights = tf.Variable(tf.random.normal([2, 1]))\n",
    "        self.bias = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "    def call(self, x):\n",
    "        logits = tf.matmul(x, self.weights) + self.bias\n",
    "        return tf.sigmoid(logits, name='output')\n",
    "\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "targets = np.array([[0], [0], [0], [1]], dtype=np.float32)\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory='./save_model', max_to_keep=1)\n",
    "\n",
    "@tf.function\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_object(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss = train_step(inputs, targets)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch {}: Loss = {}\".format(epoch, loss))\n",
    "\n",
    "    manager.save()\n",
    "\n",
    "print(\"Model saved to:\", manager.latest_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Binding inputs to tf.function `Model` failed due to `missing a required argument: 'x'`. Received args: () and kwargs: {} for signature: (x).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     logits \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmatmul(x, weights) \u001b[39m+\u001b[39m bias\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39msigmoid(logits, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m model \u001b[39m=\u001b[39m Model()\n\u001b[1;32m     20\u001b[0m checkpoint \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mCheckpoint(my_model\u001b[39m=\u001b[39mmodel)\n\u001b[1;32m     21\u001b[0m manager \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mCheckpointManager(checkpoint, directory\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./save_model\u001b[39m\u001b[39m'\u001b[39m, max_to_keep\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/env/tf1.x/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/env/tf1.x/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/function_spec.py:406\u001b[0m, in \u001b[0;36mFunctionSpec.bind_function_inputs\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m   bound_arguments \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind_with_defaults(\n\u001b[1;32m    404\u001b[0m       args, sanitized_kwargs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_values)\n\u001b[1;32m    405\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 406\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    407\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBinding inputs to tf.function `\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name\u001b[39m}\u001b[39;00m\u001b[39m` failed due to `\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived args: \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m and kwargs: \u001b[39m\u001b[39m{\u001b[39;00msanitized_kwargs\u001b[39m}\u001b[39;00m\u001b[39m for signature:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m   ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39mreturn\u001b[39;00m bound_arguments\u001b[39m.\u001b[39margs, bound_arguments\u001b[39m.\u001b[39mkwargs\n",
      "\u001b[0;31mTypeError\u001b[0m: Binding inputs to tf.function `Model` failed due to `missing a required argument: 'x'`. Received args: () and kwargs: {} for signature: (x)."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "targets = np.array([[0], [0], [0], [1]], dtype=np.float32)\n",
    "\n",
    "weights = tf.Variable(tf.random.normal([2, 1]))\n",
    "bias = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "@tf.function\n",
    "def Model(x):\n",
    "    logits = tf.matmul(x, weights) + bias\n",
    "    return tf.sigmoid(logits, name='output')\n",
    "\n",
    "model = Model()\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(my_model=model)\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory='./save_model', max_to_keep=1)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_object(targets, predictions)\n",
    "    gradients = tape.gradient(loss, [weights, bias])\n",
    "    optimizer.apply_gradients(zip(gradients, [weights, bias]))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch {}: Loss = {}\".format(epoch, loss))\n",
    "\n",
    "    manager.save()\n",
    "\n",
    "print(\"Model saved to:\", manager.latest_checkpoint)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
