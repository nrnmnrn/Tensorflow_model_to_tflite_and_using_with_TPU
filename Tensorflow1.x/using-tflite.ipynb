{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以用的程式碼在第一格，其他為測試用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tflite_runtime.interpreter as tflite\n",
    "import platform\n",
    "\n",
    "#加速棒的code\n",
    "EDGETPU_SHARED_LIB = {'Linux': 'libedgetpu.so.1' ,\n",
    "                      'Darwin': 'libedgetpu.1.dylib',\n",
    "                      'Windows': 'edgetpu.dll'}[platform.system()]\n",
    "\n",
    "def make_interpreter(model_file):\n",
    "    model_file , *device = model_file.split('@')\n",
    "    return tflite.Interpreter(model_path = model_file ,\n",
    "                              experimental_delegates = [tflite.load_delegate(EDGETPU_SHARED_LIB ,\n",
    "                                                                             {'device': device[0]} if device else {})])\n",
    "tflite_model_path = \"./final-model.tflite\"\n",
    "interpreter = make_interpreter(tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_data = np.array([[1, 0]], dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Predictions:\", output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "底下為測試用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[0.08880655]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 載入 TensorFlow Lite 模型\n",
    "tflite_model_path = \"./final-model.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# 準備輸入數據\n",
    "input_data = np.array([[1, 0]], dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# 執行推理\n",
    "interpreter.invoke()\n",
    "\n",
    "# 獲得預測結果\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Predictions:\", output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflite_runtime.interpreter as tflite\n",
    "import platform\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(images_train , labels_train) , (images_test , labels_test) = mnist.load_data()\n",
    "\n",
    "EDGETPU_SHARED_LIB = {'Linux': 'libedgetpu.so.1' ,\n",
    "                      'Darwin': 'libedgetpu.1.dylib',\n",
    "                      'Windows': 'edgetpu.dll'}[platform.system()]\n",
    "\n",
    "def make_interpreter(model_file):\n",
    "    model_file , *device = model_file.split('@')\n",
    "    return tflite.Interpreter(model_path = model_file ,\n",
    "                              experimental_delegates = [tflite.load_delegate(EDGETPU_SHARED_LIB ,\n",
    "                                                                             {'device': device[0]} if device else {})])\n",
    "\n",
    "# 載入 TensorFlow Lite 模型\n",
    "tflite_model_path = \"./final-model.tflite\"\n",
    "interpreter = make_interpreter(tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# 準備輸入數據\n",
    "input_data = np.array([[1, 0]], dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# 執行推理\n",
    "interpreter.invoke()\n",
    "\n",
    "# 獲得預測結果\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Predictions:\", output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflite_runtime.interpreter as tflite\n",
    "import platform\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(images_train , labels_train) , (images_test , labels_test) = mnist.load_data()\n",
    "\n",
    "EDGETPU_SHARED_LIB = {'Linux': 'libedgetpu.so.1' ,\n",
    "                      'Darwin': 'libedgetpu.1.dylib',\n",
    "                      'Windows': 'edgetpu.dll'}[platform.system()]\n",
    "\n",
    "def make_interpreter(model_file):\n",
    "    model_file , *device = model_file.split('@')\n",
    "    return tflite.Interpreter(model_path = model_file ,\n",
    "                              experimental_delegates = [tflite.load_delegate(EDGETPU_SHARED_LIB ,\n",
    "                                                                             {'device': device[0]} if device else {})])\n",
    "\n",
    "# ????\n",
    "model_path = os.path.join('./models/mnist_model.tflite')\n",
    "interpreter = make_interpreter(model_path)\n",
    "interpreter.allocate_tensors()\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# ??input\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\" , interpreter.get_input_details()[0]['name'])\n",
    "print(\"shape:\" , interpreter.get_input_details()[0]['shape'])\n",
    "print(\"type:\" , interpreter.get_input_details()[0]['dtype'])\n",
    "print(\"\\nDUMP INPUT\")\n",
    "print(interpreter.get_input_details()[0])\n",
    "\n",
    "# ??output\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\" , interpreter.get_output_details()[0]['name'])\n",
    "print(\"shape:\" , interpreter.get_output_details()[0]['shape'])\n",
    "print(\"type:\" , interpreter.get_output_details()[0]['dtype'])\n",
    "print(\"\\nDUMP OUTPUT\")\n",
    "print(interpreter.get_output_details()[0])\n",
    "\n",
    "\n",
    "# image load\n",
    "example_img_for_tflite = images_test[0]\n",
    "cv2.imshow('frame' , example_img_for_tflite)\n",
    "key = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "example_img_for_tflite = np.expand_dims(example_img_for_tflite , 0).astype(np.float32)\n",
    "print(\"Input data shape:\" , example_img_for_tflite.shape)\n",
    "print(\"Input data type:\" , example_img_for_tflite.dtype)\n",
    "\n",
    "# inference??\n",
    "input_details = interpreter.get_input_details()\n",
    "interpreter.set_tensor(input_details[0]['index'] , example_img_for_tflite)\n",
    "interpreter.invoke()\n",
    "output_details = interpreter.get_output_details()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"\\n\\nPrediction results:\" , output_data)\n",
    "print(\"Predicted value:\" , np.argmax(output_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yolo4 tflite\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(images_train, labels_train),(images_test, labels_test) = mnist.load_data()\n",
    "class_names = [\"zero\",\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\",\"nine\"]\n",
    "\n",
    "# ??tflite\n",
    "tflite_mnist_model = '/home/pi/my_envs/mnist_model.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path = tflite_mnist_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", interpreter.get_input_details()[0]['name'])\n",
    "print(\"shape:\", interpreter.get_input_details()[0]['shape'])\n",
    "print(\"type:\", interpreter.get_input_details()[0]['dtype'])\n",
    "\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", interpreter.get_output_details()[0]['name'])\n",
    "print(\"shape:\", interpreter.get_output_details()[0]['shape'])\n",
    "print(\"type:\", interpreter.get_output_details()[0]['dtype'])\n",
    "\n",
    "print(\"\\nDUMP INPUT\")\n",
    "print(interpreter.get_input_details()[0])\n",
    "print(\"\\nDUMP OUTPUT\")\n",
    "print(interpreter.get_output_details()[0])\n",
    "\n",
    "\n",
    "# ??????\n",
    "example_img_for_tflite = images_test[100]\n",
    "example_img_for_tflite = np.expand_dims(example_img_for_tflite,0).astype(np.float32)\n",
    "example_img_for_tflite = np.expand_dims(example_img_for_tflite,-1).astype(np.float32)\n",
    "print(\"Input data shape:\", example_img_for_tflite.shape)\n",
    "print(\"Input data type:\", example_img_for_tflite.dtype)\n",
    "input_details = interpreter.get_input_details()\n",
    "interpreter.set_tensor(input_details[0]['index'], example_img_for_tflite)\n",
    "interpreter.invoke()\n",
    "\n",
    "\n",
    "# ??????\n",
    "output_details = interpreter.get_output_details()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"\\n\\nPrediction results:\", output_data)\n",
    "print(\"Predicted value:\", np.argmax(output_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
